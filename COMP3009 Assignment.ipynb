{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600484571494",
   "display_name": "Python 3.7.9 64-bit ('comp3009': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data2020.student.csv')\n",
    "data = data.loc[0:999,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_rem = []\n",
    "to_cat = []\n",
    "num_cols = []\n",
    "cat_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 34 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   ID      1000 non-null   int64  \n 1   Class   1000 non-null   float64\n 2   C1      995 non-null    float64\n 3   C2      996 non-null    float64\n 4   C3      1000 non-null   object \n 5   C4      1000 non-null   int64  \n 6   C5      1000 non-null   object \n 7   C6      1000 non-null   int64  \n 8   C7      1000 non-null   object \n 9   C8      1000 non-null   int64  \n 10  C9      1000 non-null   int64  \n 11  C10     1000 non-null   object \n 12  C11     1000 non-null   object \n 13  C12     1000 non-null   object \n 14  C13     1000 non-null   int64  \n 15  C14     995 non-null    object \n 16  C15     1000 non-null   int64  \n 17  C16     1000 non-null   object \n 18  C17     1000 non-null   object \n 19  C18     1000 non-null   object \n 20  C19     996 non-null    object \n 21  C20     1000 non-null   int64  \n 22  C21     1000 non-null   object \n 23  C22     1000 non-null   int64  \n 24  C23     1000 non-null   object \n 25  C24     1000 non-null   int64  \n 26  C25     1000 non-null   object \n 27  C26     1000 non-null   int64  \n 28  C27     1000 non-null   object \n 29  C28     5 non-null      float64\n 30  C29     4 non-null      object \n 31  C30     1000 non-null   int64  \n 32  C31     1000 non-null   object \n 33  C32     1000 non-null   object \ndtypes: float64(4), int64(12), object(18)\nmemory usage: 265.8+ KB\n"
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "source": [
    "## Removing attributes with no information."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "C15\nC17\nC21\nC22\n"
    }
   ],
   "source": [
    "for col in data:\n",
    "    if len(data[col].value_counts()) == 1:\n",
    "        print(col)\n",
    "        to_rem.append(col)\n",
    "        data = data.drop(col,axis=1)"
   ]
  },
  {
   "source": [
    "## Determining object attributes that should be categorical"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(include=object):\n",
    "    data[col] = data[col].astype('category')\n",
    "    to_cat.append(col)"
   ]
  },
  {
   "source": [
    "## Determining numeric attributes that should be categrocial"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(include=np.number):\n",
    "    if data[col].nunique() < 5:\n",
    "        data[col] = data[col].astype('category')\n",
    "        to_cat.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 30 columns):\n #   Column  Non-Null Count  Dtype   \n---  ------  --------------  -----   \n 0   ID      1000 non-null   int64   \n 1   Class   1000 non-null   category\n 2   C1      995 non-null    float64 \n 3   C2      996 non-null    category\n 4   C3      1000 non-null   category\n 5   C4      1000 non-null   category\n 6   C5      1000 non-null   category\n 7   C6      1000 non-null   int64   \n 8   C7      1000 non-null   category\n 9   C8      1000 non-null   int64   \n 10  C9      1000 non-null   category\n 11  C10     1000 non-null   category\n 12  C11     1000 non-null   category\n 13  C12     1000 non-null   category\n 14  C13     1000 non-null   int64   \n 15  C14     995 non-null    category\n 16  C16     1000 non-null   category\n 17  C18     1000 non-null   category\n 18  C19     996 non-null    category\n 19  C20     1000 non-null   int64   \n 20  C23     1000 non-null   category\n 21  C24     1000 non-null   category\n 22  C25     1000 non-null   category\n 23  C26     1000 non-null   int64   \n 24  C27     1000 non-null   category\n 25  C28     5 non-null      category\n 26  C29     4 non-null      category\n 27  C30     1000 non-null   int64   \n 28  C31     1000 non-null   category\n 29  C32     1000 non-null   category\ndtypes: category(22), float64(1), int64(7)\nmemory usage: 87.7 KB\n"
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "source": [
    "## Setting major missing entries to dummy variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in data:\n",
    "    if (data[col].isnull().sum() / data.shape[0]) > 0.05:\n",
    "        if pd.api.types.is_categorical(data[col]):\n",
    "            data[col] = data[col].cat.add_categories('Unknown')\n",
    "            data[col] = data[col].fillna('Unknown')\n",
    "        elif pd.api.types.is_number(data[col]):\n",
    "            data[col].fillna(0)"
   ]
  },
  {
   "source": [
    "## Dropping small numbers of missing entries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 982 entries, 0 to 999\nData columns (total 30 columns):\n #   Column  Non-Null Count  Dtype   \n---  ------  --------------  -----   \n 0   ID      982 non-null    int64   \n 1   Class   982 non-null    category\n 2   C1      982 non-null    float64 \n 3   C2      982 non-null    category\n 4   C3      982 non-null    category\n 5   C4      982 non-null    category\n 6   C5      982 non-null    category\n 7   C6      982 non-null    int64   \n 8   C7      982 non-null    category\n 9   C8      982 non-null    int64   \n 10  C9      982 non-null    category\n 11  C10     982 non-null    category\n 12  C11     982 non-null    category\n 13  C12     982 non-null    category\n 14  C13     982 non-null    int64   \n 15  C14     982 non-null    category\n 16  C16     982 non-null    category\n 17  C18     982 non-null    category\n 18  C19     982 non-null    category\n 19  C20     982 non-null    int64   \n 20  C23     982 non-null    category\n 21  C24     982 non-null    category\n 22  C25     982 non-null    category\n 23  C26     982 non-null    int64   \n 24  C27     982 non-null    category\n 25  C28     982 non-null    category\n 26  C29     982 non-null    category\n 27  C30     982 non-null    int64   \n 28  C31     982 non-null    category\n 29  C32     982 non-null    category\ndtypes: category(22), float64(1), int64(7)\nmemory usage: 93.9 KB\n"
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "source": [
    "## Removing ID column "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('ID',1)"
   ]
  },
  {
   "source": [
    "## Removing duplicate data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "source": [
    "## Determining linearly independent numeric columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Columns: Index(['C1', 'C6', 'C8', 'C13', 'C20', 'C26', 'C30'], dtype='object')\nIndependent Columns: (0, 2, 3, 4, 5)\n"
    }
   ],
   "source": [
    "reduced_form, inds = sp.Matrix(data.select_dtypes(include=np.number)).rref()\n",
    "print('Columns: ' + str(data.select_dtypes(include=np.number).columns))\n",
    "print('Independent Columns: ' + str(inds))\n",
    "cols = data.select_dtypes(include=np.number).columns\n",
    "for i in range(0,len(cols)):\n",
    "    if i not in inds:\n",
    "        data = data.drop(cols[i],axis=1)\n"
   ]
  },
  {
   "source": [
    "## Assigning columns to categorical or numeric"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data:\n",
    "    if pd.api.types.is_numeric_dtype(data[col]):\n",
    "        num_cols.append(col)\n",
    "    elif col != 'Class':\n",
    "        cat_cols.append(col)"
   ]
  },
  {
   "source": [
    "## Performing hot encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataEnc = OneHotEncoder().fit(data[cat_cols].astype(str))\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(cat_cols,axis=1).join(pd.DataFrame(dataEnc.transform(data[cat_cols].astype(str)).toarray()))"
   ]
  },
  {
   "source": [
    "## Resampling to adjust for class imbalance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0    636\n1.0    246\nName: Class, dtype: int64"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0    636\n0.0    636\nName: Class, dtype: int64"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "data = data.loc[data['Class']==0,:].append(resample(data.loc[data['Class']==1,:], replace = True, n_samples = 636, random_state = 76))\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "source": [
    "## Splitting test and training \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data,test_size = 0.15,random_state = 21)"
   ]
  },
  {
   "source": [
    "## Standardising numeric training and test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataScaler = StandardScaler().fit(train_data[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[num_cols] = dataScaler.transform(train_data[num_cols])\n",
    "test_data[num_cols] = dataScaler.transform(test_data[num_cols])"
   ]
  },
  {
   "source": [
    "## Performing PCA on data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPCA = PCA().fit(train_data[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[num_cols] = dataPCA.transform(train_data[num_cols])\n",
    "test_data[num_cols] = dataPCA.transform(test_data[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               C1            C8           C13           C20           C26\nC1   1.679151e+00 -3.404684e-16 -4.605370e-16 -3.293662e-16 -3.026386e-16\nC8  -3.404684e-16  1.042176e+00  2.878356e-16 -2.500058e-16  7.195890e-18\nC13 -4.605370e-16  2.878356e-16  1.023662e+00  8.137524e-16  5.098802e-17\nC20 -3.293662e-16 -2.500058e-16  8.137524e-16  8.962536e-01 -8.635068e-18\nC26 -3.026386e-16  7.195890e-18  5.098802e-17 -8.635068e-18  3.633868e-01",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C1</th>\n      <th>C8</th>\n      <th>C13</th>\n      <th>C20</th>\n      <th>C26</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>C1</th>\n      <td>1.679151e+00</td>\n      <td>-3.404684e-16</td>\n      <td>-4.605370e-16</td>\n      <td>-3.293662e-16</td>\n      <td>-3.026386e-16</td>\n    </tr>\n    <tr>\n      <th>C8</th>\n      <td>-3.404684e-16</td>\n      <td>1.042176e+00</td>\n      <td>2.878356e-16</td>\n      <td>-2.500058e-16</td>\n      <td>7.195890e-18</td>\n    </tr>\n    <tr>\n      <th>C13</th>\n      <td>-4.605370e-16</td>\n      <td>2.878356e-16</td>\n      <td>1.023662e+00</td>\n      <td>8.137524e-16</td>\n      <td>5.098802e-17</td>\n    </tr>\n    <tr>\n      <th>C20</th>\n      <td>-3.293662e-16</td>\n      <td>-2.500058e-16</td>\n      <td>8.137524e-16</td>\n      <td>8.962536e-01</td>\n      <td>-8.635068e-18</td>\n    </tr>\n    <tr>\n      <th>C26</th>\n      <td>-3.026386e-16</td>\n      <td>7.195890e-18</td>\n      <td>5.098802e-17</td>\n      <td>-8.635068e-18</td>\n      <td>3.633868e-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "train_data[num_cols].cov()"
   ]
  },
  {
   "source": [
    "## Using LOF to remove outliers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cLOF = LocalOutlierFactor(n_neighbors=6,metric='manhattan').fit_predict(train_data)\n",
    "train_data = train_data.loc[cLOF==1,:]"
   ]
  },
  {
   "source": [
    "## Performing cluster analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6,random_state=67).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Cluster'] = kmeans.predict(train_data)\n",
    "test_data['Cluster'] = kmeans.predict(test_data)"
   ]
  },
  {
   "source": [
    "## Test analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop('Class',axis=1)\n",
    "y_train = train_data['Class']\n",
    "x_test = test_data.drop('Class',axis=1)\n",
    "y_test = test_data['Class']"
   ]
  },
  {
   "source": [
    "k-Nearest Neighbours Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7068062827225131"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "sum(knn.predict(x_test) == y_test)/len(y_test)"
   ]
  },
  {
   "source": [
    "Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.743455497382199"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "sum(clf.predict(x_test) == y_test)/len(y_test)"
   ]
  },
  {
   "source": [
    "Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(70, 10)).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5026178010471204"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "sum(cnn.predict(x_test) == y_test)/len(y_test)"
   ]
  },
  {
   "source": [
    "Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = RandomForestClassifier().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9057591623036649"
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "sum(crf.predict(x_test) == y_test)/len(y_test)"
   ]
  },
  {
   "source": [
    "Medley Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## TODO \n",
    "- Optimise hyper-parameters\n",
    "- Experiment with further medley models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}