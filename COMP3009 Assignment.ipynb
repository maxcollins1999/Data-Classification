{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600411978620",
   "display_name": "Python 3.7.9 64-bit ('comp3009': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data2020.student.csv')\n",
    "data = data.loc[0:999,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_rem = []\n",
    "to_cat = []\n",
    "num_cols = []\n",
    "cat_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 34 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   ID      1000 non-null   int64  \n 1   Class   1000 non-null   float64\n 2   C1      995 non-null    float64\n 3   C2      996 non-null    float64\n 4   C3      1000 non-null   object \n 5   C4      1000 non-null   int64  \n 6   C5      1000 non-null   object \n 7   C6      1000 non-null   int64  \n 8   C7      1000 non-null   object \n 9   C8      1000 non-null   int64  \n 10  C9      1000 non-null   int64  \n 11  C10     1000 non-null   object \n 12  C11     1000 non-null   object \n 13  C12     1000 non-null   object \n 14  C13     1000 non-null   int64  \n 15  C14     995 non-null    object \n 16  C15     1000 non-null   int64  \n 17  C16     1000 non-null   object \n 18  C17     1000 non-null   object \n 19  C18     1000 non-null   object \n 20  C19     996 non-null    object \n 21  C20     1000 non-null   int64  \n 22  C21     1000 non-null   object \n 23  C22     1000 non-null   int64  \n 24  C23     1000 non-null   object \n 25  C24     1000 non-null   int64  \n 26  C25     1000 non-null   object \n 27  C26     1000 non-null   int64  \n 28  C27     1000 non-null   object \n 29  C28     5 non-null      float64\n 30  C29     4 non-null      object \n 31  C30     1000 non-null   int64  \n 32  C31     1000 non-null   object \n 33  C32     1000 non-null   object \ndtypes: float64(4), int64(12), object(18)\nmemory usage: 265.8+ KB\n"
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "source": [
    "## Removing attributes with no information."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "C15\nC17\nC21\nC22\n"
    }
   ],
   "source": [
    "for col in data:\n",
    "    if len(data[col].value_counts()) == 1:\n",
    "        print(col)\n",
    "        to_rem.append(col)\n",
    "        data = data.drop(col,axis=1)"
   ]
  },
  {
   "source": [
    "## Determining object attributes that should be categorical"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(include=object):\n",
    "    data[col] = data[col].astype('category')\n",
    "    to_cat.append(col)"
   ]
  },
  {
   "source": [
    "## Determining numeric attributes that should be categrocial"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(include=np.number):\n",
    "    if data[col].nunique() < 5:\n",
    "        data[col] = data[col].astype('category')\n",
    "        to_cat.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 30 columns):\n #   Column  Non-Null Count  Dtype   \n---  ------  --------------  -----   \n 0   ID      1000 non-null   int64   \n 1   Class   1000 non-null   category\n 2   C1      995 non-null    float64 \n 3   C2      996 non-null    category\n 4   C3      1000 non-null   category\n 5   C4      1000 non-null   category\n 6   C5      1000 non-null   category\n 7   C6      1000 non-null   int64   \n 8   C7      1000 non-null   category\n 9   C8      1000 non-null   int64   \n 10  C9      1000 non-null   category\n 11  C10     1000 non-null   category\n 12  C11     1000 non-null   category\n 13  C12     1000 non-null   category\n 14  C13     1000 non-null   int64   \n 15  C14     995 non-null    category\n 16  C16     1000 non-null   category\n 17  C18     1000 non-null   category\n 18  C19     996 non-null    category\n 19  C20     1000 non-null   int64   \n 20  C23     1000 non-null   category\n 21  C24     1000 non-null   category\n 22  C25     1000 non-null   category\n 23  C26     1000 non-null   int64   \n 24  C27     1000 non-null   category\n 25  C28     5 non-null      category\n 26  C29     4 non-null      category\n 27  C30     1000 non-null   int64   \n 28  C31     1000 non-null   category\n 29  C32     1000 non-null   category\ndtypes: category(22), float64(1), int64(7)\nmemory usage: 87.7 KB\n"
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "source": [
    "## Setting major missing entries to dummy variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in data:\n",
    "    if (data[col].isnull().sum() / data.shape[0]) > 0.05:\n",
    "        if pd.api.types.is_categorical(data[col]):\n",
    "            data[col] = data[col].cat.add_categories('Unknown')\n",
    "            data[col] = data[col].fillna('Unknown')\n",
    "        elif pd.api.types.is_number(data[col]):\n",
    "            data[col].fillna(0)"
   ]
  },
  {
   "source": [
    "## Dropping small numbers of missing entries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 982 entries, 0 to 999\nData columns (total 30 columns):\n #   Column  Non-Null Count  Dtype   \n---  ------  --------------  -----   \n 0   ID      982 non-null    int64   \n 1   Class   982 non-null    category\n 2   C1      982 non-null    float64 \n 3   C2      982 non-null    category\n 4   C3      982 non-null    category\n 5   C4      982 non-null    category\n 6   C5      982 non-null    category\n 7   C6      982 non-null    int64   \n 8   C7      982 non-null    category\n 9   C8      982 non-null    int64   \n 10  C9      982 non-null    category\n 11  C10     982 non-null    category\n 12  C11     982 non-null    category\n 13  C12     982 non-null    category\n 14  C13     982 non-null    int64   \n 15  C14     982 non-null    category\n 16  C16     982 non-null    category\n 17  C18     982 non-null    category\n 18  C19     982 non-null    category\n 19  C20     982 non-null    int64   \n 20  C23     982 non-null    category\n 21  C24     982 non-null    category\n 22  C25     982 non-null    category\n 23  C26     982 non-null    int64   \n 24  C27     982 non-null    category\n 25  C28     982 non-null    category\n 26  C29     982 non-null    category\n 27  C30     982 non-null    int64   \n 28  C31     982 non-null    category\n 29  C32     982 non-null    category\ndtypes: category(22), float64(1), int64(7)\nmemory usage: 93.9 KB\n"
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "source": [
    "## Removing ID column "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('ID',1)"
   ]
  },
  {
   "source": [
    "## Removing duplicate data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "source": [
    "## Determining linearly independent numeric columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Columns: Index(['C1', 'C6', 'C8', 'C13', 'C20', 'C26', 'C30'], dtype='object')\nIndependent Columns: (0, 2, 3, 4, 5)\n"
    }
   ],
   "source": [
    "reduced_form, inds = sp.Matrix(data.select_dtypes(include=np.number)).rref()\n",
    "print('Columns: ' + str(data.select_dtypes(include=np.number).columns))\n",
    "print('Independent Columns: ' + str(inds))\n",
    "cols = data.select_dtypes(include=np.number).columns\n",
    "for i in range(0,len(cols)):\n",
    "    if i not in inds:\n",
    "        data = data.drop(cols[i],axis=1)\n"
   ]
  },
  {
   "source": [
    "## Assigning columns to categorical or numeric"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data:\n",
    "    if pd.api.types.is_numeric_dtype(data[col]):\n",
    "        num_cols.append(col)\n",
    "    elif col != 'Class':\n",
    "        cat_cols.append(col)"
   ]
  },
  {
   "source": [
    "## Performing hot encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataEnc = OneHotEncoder().fit(data[cat_cols].astype(str))\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(cat_cols,axis=1).join(pd.DataFrame(dataEnc.transform(data[cat_cols].astype(str)).toarray()))"
   ]
  },
  {
   "source": [
    "## Splitting test and training \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data.loc[0:999,:],test_size = 0.15,random_state = 21)"
   ]
  },
  {
   "source": [
    "## Standardising numeric training and test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataScaler = StandardScaler().fit(train_data[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[num_cols] = dataScaler.transform(train_data[num_cols])\n",
    "test_data[num_cols] = dataScaler.transform(test_data[num_cols])"
   ]
  },
  {
   "source": [
    "## Performing PCA on data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPCA = PCA().fit(train_data[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[num_cols] = dataPCA.transform(train_data[num_cols])\n",
    "test_data[num_cols] = dataPCA.transform(test_data[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               C1            C8           C13           C20           C26\nC1   1.646307e+00  1.977770e-16  3.799694e-17 -1.306145e-16  1.923595e-16\nC8   1.977770e-16  1.062239e+00  6.768205e-17  2.190761e-16  1.270523e-16\nC13  3.799694e-17  6.768205e-17  1.006882e+00  1.899847e-17 -9.380494e-17\nC20 -1.306145e-16  2.190761e-16  1.899847e-17  9.270424e-01 -1.306145e-17\nC26  1.923595e-16  1.270523e-16 -9.380494e-17 -1.306145e-17  3.642139e-01",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C1</th>\n      <th>C8</th>\n      <th>C13</th>\n      <th>C20</th>\n      <th>C26</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>C1</th>\n      <td>1.646307e+00</td>\n      <td>1.977770e-16</td>\n      <td>3.799694e-17</td>\n      <td>-1.306145e-16</td>\n      <td>1.923595e-16</td>\n    </tr>\n    <tr>\n      <th>C8</th>\n      <td>1.977770e-16</td>\n      <td>1.062239e+00</td>\n      <td>6.768205e-17</td>\n      <td>2.190761e-16</td>\n      <td>1.270523e-16</td>\n    </tr>\n    <tr>\n      <th>C13</th>\n      <td>3.799694e-17</td>\n      <td>6.768205e-17</td>\n      <td>1.006882e+00</td>\n      <td>1.899847e-17</td>\n      <td>-9.380494e-17</td>\n    </tr>\n    <tr>\n      <th>C20</th>\n      <td>-1.306145e-16</td>\n      <td>2.190761e-16</td>\n      <td>1.899847e-17</td>\n      <td>9.270424e-01</td>\n      <td>-1.306145e-17</td>\n    </tr>\n    <tr>\n      <th>C26</th>\n      <td>1.923595e-16</td>\n      <td>1.270523e-16</td>\n      <td>-9.380494e-17</td>\n      <td>-1.306145e-17</td>\n      <td>3.642139e-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "train_data[num_cols].cov()"
   ]
  },
  {
   "source": [
    "## Test analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop('Class',axis=1)\n",
    "y_train = train_data['Class']\n",
    "x_test = test_data.drop('Class',axis=1)\n",
    "y_test = test_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6766917293233082"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "sum(knn.predict(x_test) == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7593984962406015"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "sum(clf.predict(x_test) == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(30, 3)).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7669172932330827"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "sum(cnn.predict(x_test) == y_test)/len(y_test)"
   ]
  },
  {
   "source": [
    "## TODO \n",
    "- Use LOF to isolate outliers in training and test\n",
    "- Change sampling technique to improve data representation\n",
    "- Cluster training data and append cluster to data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}